项目：泰坦尼克号乘客幸存率

在此预测中，我们首先分析了数据以发现年龄，性别，类别以及配偶，子女和兄弟的数量是生存的重要因素，因此我们进行了深入分析，以影响影响生存的重要因素率：
1.未满10岁的乘客可以生存
2.一，二等舱女乘客首先生存。亲属数为0时，三等女性的成活率更高。
3.年龄在20至45岁之间的乘客生存率更高

通过分析数据的特征，初步调试将预测准确率提高到80.81％。同时，由于在这种情况下只有两个输出结果，因此我们使用线性分类器进行预测。结果为80.26％，表明该决策树算法更适合这种情况。

优点
1.通过对数据的深入分析，合理划分分支机构可以快速提高预测的准确性，易于理解和解释，因为可以放置和看到树状图
2.需要很少的数据准备。许多其他算法通常需要数据规范化，创建伪变量并删除空值。但是请注意，sklearn中的决策树模块不支持删除值的处理。
3.使用树的成本（例如，在预测数据时）是用于训练树的数据点数量的对数，与其他算法划分，这是非常低的成本。
4.能够处理数字和分类数据，以进行回归和分类。通常使用其他技术来分析仅具有一种变量类型的数据集。
5.能够处理多个输出问题，即多个标签的问题，注意区别于一个标签中多个标签的问题
6.这是一个白盒模型，其结果很容易解释。如果可以在模型中观察到给定情况，则可以通过布尔逻辑轻松解释条件。

缺点
1，仅对数据的6个分支进行了划分，导致精度较低，但满足了问题的要求。即使其假设在某种程度上违反了所生成数据的真实模型，也可以表现良好。
2.决策树学习者可能会创建过于复杂的树，从而无法很好地概括数据。这称为过度拟合。为了避免此问题，必须使用诸如修剪，设置叶节点所需的最少样本数量或设置树的最大深度之类的机制，而对于初学者而言，这些参数的集成和调整将更加晦涩难懂。
3决策树可能不稳定，数据中的微小变化可能导致生成完全不同的树。这个问题需要通过集成算法来解决。

总结
此项目中应用的技术是简单的机器学习模型（决策树）的手动实现。决策树一次按一个功能将一组数据分成越来越小的组。每当每个数据子集被分割时，如果每个结果子组比以前更均质（包含相似标签） ，我们的预测将变得更加精确。在彼得先生的指导下，我对机器学习的理论框架和发展现状有了基本的了解。在老师对代码用例进行深入分析之后，我对Python有了初步的了解。
